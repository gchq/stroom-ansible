

# Stroom configuration file
# =========================

# For information on the structure of this configuration file see:
# https://www.dropwizard.io/en/latest/manual/configuration.html
# For information on the logback logFormat strings see:
# http://logback.qos.ch/manual/layouts.html

# This configuration file was made for the docker distribution.

# This section is the DropWizard configuration for Stroom

server:
  applicationContextPath: "${APPLICATION_CONTEXT_PATH:-/}"
  adminContextPath: "${ADMIN_CONTEXT_PATH:-/stroomAdmin}"
  applicationConnectors:
    - type: http
      port: ${STROOM_APP_PORT:-8080}
  adminConnectors:
    - type: http
      port: ${STROOM_ADMIN_PORT:-8081}

  requestLog:
    appenders:
      # Log appender for the web server request logging
    - type: file
      currentLogFilename: logs/access/access.log
      threshold: ALL
      queueSize: 256
      discardingThreshold: 0
      archive: true
      # Rolled and gzipped every minute
      archivedLogFilenamePattern: logs/access/access-%d{yyyy-MM-dd'T'HH:mm}.log.gz
      archivedFileCount: 100
      timeZone: UTC
      logFormat: '%h %l "%u" [%t] "%r" %s %b "%i{Referer}" "%i{User-Agent}" %D'

logging:
  level: "${STROOM_LOGGING_LEVEL:-WARN}"
  loggers:
    stroom: INFO
    io.dropwizard: INFO
    org.eclipse.jetty: INFO
    org.glassfish: INFO
    org.glassfish.jersey: INFO
    # Comment this out if you want logging of the REST request/responses
    # NOT recommended for production environments as it is very verbose
    org.glassfish.jersey.logging.LoggingFeature: "OFF"
    #    org.glassfish.jersey.server.ServerRuntime.Responder: INFO
    #    org.glassfish.jersey.server.validation.internal.ValidationExceptionMapper: FINER
    org.flywaydb: INFO
    # Logger and appender for audit logs
    "event-logger":
      level: INFO
      additive: false
      appenders:
        - type: file
          currentLogFilename: logs/user/user.log
          threshold: ALL
          queueSize: 256
          discardingThreshold: 0
          archive: true
          # Rolled every minute
          archivedLogFilenamePattern: logs/user/user-%d{yyyy-MM-dd'T'HH:mm}.log
          archivedFileCount: 100
          timeZone: UTC
          logFormat: "%msg%n"
    # Logger and appender for the flyway DB migration SQL output
    org.flywaydb.core.internal.sqlscript:
      level: DEBUG
      additive: false
      appenders:
        - type: file
          currentLogFilename: logs/migration/migration.log
          threshold: ALL
          queueSize: 256
          discardingThreshold: 0
          archive: true
          # Rolled every day
          archivedLogFilenamePattern: logs/migration/migration-%d{yyyy-MM-dd}.log
          archivedFileCount: 10
          timeZone: UTC
          logFormat: "%-6level [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%t] %logger - %X{code} %msg %n"

  appenders:


  # stdout for docker
  - type: console
    # Multi-coloured log format for console output
    logFormat: "%highlight(%-6level) [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%green(%t)] %cyan(%logger) - %X{code} %msg %n"
    timeZone: UTC


    # Minute rolled files for stroom/datafeed, will be curl'd/deleted by stroom-log-sender
  - type: file
    currentLogFilename: logs/app/app.log
    threshold: ALL
    queueSize: 256
    discardingThreshold: 0
    archive: true
    # Rolled and gzipped every minute
    archivedLogFilenamePattern: logs/app/app-%d{yyyy-MM-dd'T'HH:mm}.log.gz
    # One week using minute files
    archivedFileCount: 10080
    timeZone: UTC
    logFormat: "%-6level [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%t] %logger - %X{code} %msg %n"



# This section contains the Stroom configuration properties
# For more information see:
# https://gchq.github.io/stroom-docs/user-guide/properties.html

appConfig:
  commonDbDetails:
    connection:
      jdbcDriverClassName: "${STROOM_JDBC_DRIVER_CLASS_NAME:-com.mysql.cj.jdbc.Driver}"
      jdbcDriverUrl: "${STROOM_JDBC_DRIVER_URL:-jdbc:mysql://localhost:3307/stroom?useUnicode=yes&characterEncoding=UTF-8}"
      jdbcDriverUsername: "${STROOM_JDBC_DRIVER_USERNAME:-stroomuser}"
      jdbcDriverPassword: "${STROOM_JDBC_DRIVER_PASSWORD:-stroompassword1}"
  contentPackImport:
    enabled: ${STROOM_CONTENT_PACK_IMPORT_ENABLED:-false}
  job:
    enabled: true
    enableDistributedJobsOnBootstrap: ${STROOM_DISTRIBUTED_JOBS_ENABLED_ON_BOOTSTRAP:-true}
    executionInterval: "10s"
  node:
    # The name for the node, should be unique to each node in the cluster
    name: "{{ inventory_hostname_short  }}"
    #name: "node1a"
  # The address of the this node for inter-node communication
  nodeUri:
    hostname: "${STROOM_HOST:-localhost}"
  path:
    home: "/stroom"
    temp: "/tmp/stroom"
  # The public address for stroom, typically the public address of nginx
  publicUri:
    hostname: "${API_GATEWAY_HOST:-localhost}"
    port: "${API_GATEWAY_PORT:-443}"
  security:
    authentication:
      preventLogin: false
    identity:
      useDefaultOpenIdCredentials: "${USE_DEFAULT_OPEN_ID_CREDENTIALS:-false}"
  serviceDiscovery:
    enabled: "${STROOM_SERVICE_DISCOVERY_ENABLED:-false}"
    zookeeperUrl: "${STROOM_SERVICE_DISCOVERY_ZOOKEEPER_URL:-localhost:2181}"
  statistics:
    hbase:
      kafkaConfigUuid:
    internal:
      enabledStoreTypes: ${STROOM_ENABLED_STAT_STORE_TYPES:-[ "StatisticStore" ]}
    sql:
      db:
        connection:
          jdbcDriverClassName: "${STROOM_STATISTICS_JDBC_DRIVER_CLASS_NAME:-com.mysql.cj.jdbc.Driver}"
          jdbcDriverUrl: "${STROOM_STATISTICS_JDBC_DRIVER_URL:-jdbc:mysql://localhost:3307/stats?useUnicode=yes&characterEncoding=UTF-8}"
          jdbcDriverUsername: "${STROOM_STATISTICS_JDBC_DRIVER_USERNAME:-statsuser}"
          jdbcDriverPassword: "${STROOM_STATISTICS_JDBC_DRIVER_PASSWORD:-stroompassword1}"

# vim: set filetype=yaml tabstop=2 shiftwidth=2 expandtab:
